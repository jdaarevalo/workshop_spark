{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extract Information PySpark\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## *Instructor: José David Arévalo*\n",
    "\n",
    "- email: <jdaarevalo@gmail.com>\n",
    "- twitter: [@jdaarevalo](https://twitter.com/jdaarevalo)\n",
    "- linkedin: [jdavidarevalo](https://www.linkedin.com/in/jdavidarevalo/)\n",
    "- github: [jdaarevalo](https://github.com/jdaarevalo)\n",
    "\n",
    "\n",
    "\n",
    "###### Octubre 05, 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los modulos necesarios\n",
    "import pyspark  #python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si no logra hacer el import de pyspark, sera necesario instalarlo\n",
    "# usar !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objeto principal o la base a partir de la cual cuelga toda la funcionalidad de Apache Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Se trata del context básico de Spark, desde donde se crean el resto de variables \n",
    "# que maneja el framework. Sólo un SparkContext puede estar activo por JVM.\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# el objeto functions del modulo sql define las funciones estándar incorporadas \n",
    "# para trabajar con (valores producidos) columnas.\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new spark session, que sera la base para nuestra aplicacion\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "                    .appName(\"Test\")\\\n",
    "                    .getOrCreate()\n",
    "\n",
    "#spark sera el punto de entrada para la aplicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10ab0eb00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtrain.csv\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read table postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new spark session, que sera la base para nuestra aplicacion\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "                    .appName(\"Test\")\\\n",
    "                    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:9.4.1211\")\\\n",
    "                    .getOrCreate()\n",
    "\n",
    "#spark sera el punto de entrada para la aplicacion\n",
    "# el package se pude descargar de https://jdbc.postgresql.org/download.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables de conexion a la base de datos\n",
    "jdbcPort = 5432                                                                           \n",
    "\n",
    "jdbcHostname = \"ec2-54-227-251-33.compute-1.amazonaws.com\"\n",
    "jdbcDatabase = \"d2v7jfobmmd2o7\"                                       \n",
    "jdbcUsername= \"sjkkapmzuixjbz\"                                                              \n",
    "jdbcPassword= \"2995eb07a249a61fcf4035f967d57979550b77c6756929410db3b37c50de7a5e\"\n",
    "# jdbc url para conectarse a la base de datos\n",
    "jdbcUrl = \"jdbc:postgresql://{0}:{1}/{2}\".format(jdbcHostname, jdbcPort, jdbcDatabase)\n",
    "\n",
    "# propiedades para la conexion a la base de datos\n",
    "connectionProperties = {                                                                  \n",
    "  \"user\" : jdbcUsername,\n",
    "  \"password\" : jdbcPassword,\n",
    "  \"driver\": 'org.postgresql.Driver',\n",
    "  \"ssl\":'true',\n",
    "  \"sslfactory\":'org.postgresql.ssl.NonValidatingFactory',\n",
    "  \"stringtype\": \"unspecified\"                                                             \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"(SELECT * FROM pg_catalog.pg_tables) AS data_table\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tables = spark.read.jdbc(url=jdbcUrl,\n",
    "                              table=query,\n",
    "                              properties=connectionProperties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------------+----------+----------+--------+-----------+-----------+\n",
      "|schemaname|       tablename|    tableowner|tablespace|hasindexes|hasrules|hastriggers|rowsecurity|\n",
      "+----------+----------------+--------------+----------+----------+--------+-----------+-----------+\n",
      "|pg_catalog|    pg_statistic|      postgres|      null|      true|   false|      false|      false|\n",
      "|    public|        category|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|pg_catalog|pg_foreign_table|      postgres|      null|      true|   false|      false|      false|\n",
      "|    public|            city|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|           event|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|           group|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|pg_catalog|       pg_authid|      postgres| pg_global|      true|   false|      false|      false|\n",
      "|    public|     group_topic|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|          member|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|    member_topic|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|           topic|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|           venue|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|pg_catalog| pg_user_mapping|      postgres|      null|      true|   false|      false|      false|\n",
      "|pg_catalog| pg_subscription|      postgres| pg_global|      true|   false|      false|      false|\n",
      "|pg_catalog|  pg_largeobject|      postgres|      null|      true|   false|      false|      false|\n",
      "|pg_catalog|         pg_type|      postgres|      null|      true|   false|      false|      false|\n",
      "|pg_catalog|    pg_attribute|      postgres|      null|      true|   false|      false|      false|\n",
      "|pg_catalog|         pg_proc|      postgres|      null|      true|   false|      false|      false|\n",
      "|pg_catalog|        pg_class|      postgres|      null|      true|   false|      false|      false|\n",
      "|pg_catalog|      pg_attrdef|      postgres|      null|      true|   false|      false|      false|\n",
      "+----------+----------------+--------------+----------+----------+--------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tables.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"(SELECT * FROM pg_catalog.pg_tables where tableowner = 'sjkkapmzuixjbz') AS data_table\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tables = spark.read.jdbc(url=jdbcUrl,\n",
    "                              table=query,\n",
    "                              properties=connectionProperties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+----------+----------+--------+-----------+-----------+\n",
      "|schemaname|   tablename|    tableowner|tablespace|hasindexes|hasrules|hastriggers|rowsecurity|\n",
      "+----------+------------+--------------+----------+----------+--------+-----------+-----------+\n",
      "|    public|    category|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|        city|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|       event|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|       group|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public| group_topic|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|      member|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|member_topic|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|       topic|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "|    public|       venue|sjkkapmzuixjbz|      null|     false|   false|      false|      false|\n",
      "+----------+------------+--------------+----------+----------+--------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tables.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
